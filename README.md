```markdown
# ğŸ•·ï¸ Multithreaded Image Scraper & Data Extractor

A fully modular, multithreaded, and production-ready web scraping system in Python. It is designed to **log in to a website**, **extract paginated image content**, **download images concurrently**, and **log all activity** while also **exporting structured product data to Excel**.

> âš™ï¸ Designed for extensibility, performance, and clarity.

---

## ğŸ“Œ Features

âœ… Authenticated scraping with CSRF token support  
âœ… Thread-safe image downloading with locking and semaphores  
âœ… Pagination-aware URL generation  
âœ… Real-time console logging + log file creation  
âœ… Config-based architecture using `.env` for credentials  
âœ… Structured data export to Excel via `xlsxwriter`  
âœ… CLI loading spinner for user feedback

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ scrapper/                # Core scraping logic
â”‚   â”œâ”€â”€ config.py            # Configuration loader
â”‚   â”œâ”€â”€ session_manager.py   # Login and session management
â”‚   â”œâ”€â”€ extractor.py         # Image URL extraction logic
â”‚   â”œâ”€â”€ downloader.py        # Image downloader using threading
â”‚   â”œâ”€â”€ controller.py        # Central runner with thread orchestration
â”‚
â”œâ”€â”€ utils/                   # Utility tools
â”‚   â”œâ”€â”€ excel_writer.py      # Excel export handler
â”‚   â”œâ”€â”€ spinner.py           # CLI spinner
â”‚
â”œâ”€â”€ logs.txt                 # Output log file
â”œâ”€â”€ .env                     # Configuration secrets
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Project documentation
```

---

## ğŸ”§ Setup Instructions

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/image-scraper.git
cd image-scraper
```

2. **Create and activate virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Configure your `.env` file**

```env
USER_AGENT=your_user_agent
BASE_URL=https://example.com
LOGIN_URL=https://example.com/login
PAGE_URL=https://example.com/page=
LOGIN_USERNAME=your_username
PASSWORD=your_password
```

---

## ğŸš€ Running the App

```bash
python controller.py
```

This will:
- Log in to the website
- Extract image URLs from each page
- Download all images concurrently to `_images/`
- Export product data to `config/data.xlsx`
- Output logs to `logs.txt`

---

## ğŸ“Š Excel Output Example

Your extracted data is saved as an Excel file with the following structure:

| Name       | Code     | Image URL                 |
|------------|----------|---------------------------|
| Product 1  | #A32KLS  | https://example.com/1.jpg |
| Product 2  | #8FJK1D  | https://example.com/2.jpg |

---

## ğŸ§  Tech Stack

- `requests` + `BeautifulSoup4` â€” HTTP & HTML parsing
- `threading`, `Lock`, `Semaphore` â€” Concurrency
- `uuid`, `pathlib` â€” Unique filenames and platform-safe paths
- `xlsxwriter` â€” Excel export
- `decouple` â€” Secure configuration management

---

## ğŸ’¡ Design Philosophy

This scraper is structured with **scalability and reusability** in mind. You can easily adapt it to:
- Extract other types of content (e.g., text, metadata)
- Integrate with databases or cloud storage
- Convert it to use `asyncio + aiohttp` for async scraping

---

## ğŸ“Œ Future Enhancements

- ğŸ”„ Replace `threading` with `asyncio` for I/O-bound performance
- ğŸ’¾ Add support for SQLite/CSV exports
- ğŸ“¸ Use `Pillow` for validating image formats after download
- ğŸ›¡ï¸ Retry logic & CAPTCHA detection bypass

---

## ğŸ§‘â€ğŸ’» Author

**Nurdan**  
Data Science undergraduate @ University of Manitoba  
ğŸ’¼ Career goal: Machine Learning Engineer  
ğŸ“« Contact: [your email or GitHub profile]

---

